{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWoVWVGRll0M"
      },
      "source": [
        "# Run (un)mitigated QV experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkVopiACnMbk"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import mitiq\n",
        "except ImportError:\n",
        "    !pip install mitiq --quiet\n",
        "\n",
        "try:\n",
        "    import qiskit\n",
        "except ImportError:\n",
        "    !pip install qiskit --quiet\n",
        "\n",
        "try:\n",
        "    import qiskit_experiments\n",
        "except ImportError:\n",
        "    !pip uninstall matplotlib -y\n",
        "    !pip install qiskit-experiments --quiet\n",
        "    !pip install matplotlib~=3.4.0"
      ],
      "metadata": {
        "id": "1hctUGMxCFJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaqGfgzRltU3"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "from typing import Iterable, List, Set\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import qiskit\n",
        "import qiskit_experiments.library.quantum_volume as qv\n",
        "\n",
        "from mitiq import zne"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    _ = qiskit.IBMQ.load_account()\n",
        "except Exception:\n",
        "    print(\"IBMQ account not found.\")"
      ],
      "metadata": {
        "id": "e3490F9xFJIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4M4c3FM_CGe"
      },
      "source": [
        "### Quantum volume functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsmxYsbzw0o-"
      },
      "outputs": [],
      "source": [
        "def get_heavy_bitstrings(circuit: qiskit.QuantumCircuit) -> Set[str]:\n",
        "    job = qiskit.execute(circuit, backend=qiskit.BasicAer.get_backend(\"statevector_simulator\"))\n",
        "\n",
        "    probs = list(job.result().get_counts().items())\n",
        "    median = np.median([p for (_, p) in probs])\n",
        "    return set(bitstring for (bitstring, p) in probs if p > median)\n",
        "\n",
        "\n",
        "def estimate_heavy_output(\n",
        "    circuits: List[qiskit.QuantumCircuit],\n",
        "    backend: \"qiskit.Sampler\",\n",
        "    qubits: List[int],\n",
        "    nshots: int = 10_000,\n",
        "    measure_all: bool = True,\n",
        "    verbose: bool = False,\n",
        ") -> List[float]:   \n",
        "    circuits = [qiskit.transpile(circuit, basis_gates=[\"u1\", \"u2\", \"u3\", \"cx\"], optimization_level=0) for circuit in circuits]\n",
        "\n",
        "    # Determine the heavy bitstrings.\n",
        "    heavy_bitstrings = [get_heavy_bitstrings(circuit) for circuit in circuits]\n",
        "\n",
        "    if measure_all:\n",
        "        for circuit in circuits:\n",
        "            circuit.measure_all()\n",
        "\n",
        "    # Run all circuits.\n",
        "    job = qiskit.execute(\n",
        "        circuits,\n",
        "        backend=backend,\n",
        "        initial_layout=qubits,\n",
        "        shots=nshots,\n",
        "        optimization_level=0,\n",
        "    )\n",
        "\n",
        "    # Count the number of heavy bitstrings sampled on the backend.\n",
        "    heavy_counts = []\n",
        "    for i in range(len(circuits)):\n",
        "        heavy_counts.append(\n",
        "            sum([job.result().get_counts(i).get(bitstring, 0) for bitstring in heavy_bitstrings[i]])\n",
        "        )\n",
        "    return heavy_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlX9L9Tb3LBZ",
        "tags": []
      },
      "source": [
        "## Set experiment parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9D2kc0E4_iK"
      },
      "outputs": [],
      "source": [
        "# Notebook parameters.\n",
        "MAX_BATCH_SIZE = 100\n",
        "save_data = False\n",
        "\n",
        "# Quantum volume parameters.\n",
        "# backend = qiskit.IBMQ.get_provider(hub=\"your\", group=\"credentials\", project=\"here\").get_backend(\"ibmq_quito\")\n",
        "#backend = qiskit.test.mock.FakeQuito()\n",
        "backend = qiskit.providers.fake_provider.FakeQuito()\n",
        "test_qubits = [\n",
        "    [0, 1, 2],\n",
        "    [0, 1, 3],\n",
        "    [1, 3, 4],\n",
        "    [0, 1, 2, 3],\n",
        "    [0, 1, 3, 4],\n",
        "    [0, 1, 2, 3, 4]\n",
        "]\n",
        "ntrials = 500\n",
        "nshots = 10_000\n",
        "\n",
        "# ZNE parameters.\n",
        "scale_factors = [1, 3, 5, 7, 9]\n",
        "fit = lambda s: zne.inference.RichardsonFactory(s)\n",
        "scale_noise = functools.partial(\n",
        "    zne.scaling.fold_gates_at_random,\n",
        "    fidelities={\"single\": 1.0},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p114946buLVY",
        "tags": []
      },
      "source": [
        "## Run experiment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batching for raw experiment.\n",
        "njobs = ntrials // MAX_BATCH_SIZE\n",
        "step = MAX_BATCH_SIZE\n",
        "\n",
        "# Batching for mitigated experiment.\n",
        "njobs_zne = ntrials * len(scale_factors) // MAX_BATCH_SIZE\n",
        "step_zne = MAX_BATCH_SIZE // len(scale_factors)\n",
        "nshots_zne = nshots // len(scale_factors)"
      ],
      "metadata": {
        "id": "675fOpj9JMT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMn5DhEMyKyv"
      },
      "outputs": [],
      "source": [
        "all_raw_counts = []\n",
        "all_scaled_counts = []\n",
        "\n",
        "for qubits in test_qubits:\n",
        "    print(\"Testing qubits\", qubits)\n",
        "    # Generate circuits.\n",
        "    circuits = [\n",
        "        qv.qv_experiment.QuantumVolumeCircuit(\n",
        "            num_qubits=len(qubits),\n",
        "            depth=len(qubits),\n",
        "            seed=seed,\n",
        "            classical_permutation=True,\n",
        "        ) for seed in range(ntrials)\n",
        "    ]\n",
        "    circuits = [\n",
        "        qiskit.transpile(circuit, basis_gates=[\"u1\", \"u2\", \"u3\", \"cx\"], optimization_level=3)\n",
        "        for circuit in circuits\n",
        "    ]\n",
        "\n",
        "    # Raw experiment.\n",
        "    heavy_output_counts = []\n",
        "    for i in range(njobs):\n",
        "        to_run = circuits[i * step: (i + 1) * step]\n",
        "        print(\"\\r\", end=f\"Running QV batch {i + 1} / {njobs} with {len(to_run)} circuit(s).\")\n",
        "        heavy_output_counts.extend(\n",
        "            estimate_heavy_output(to_run, backend=backend, qubits=qubits, nshots=nshots)\n",
        "        )\n",
        "    all_raw_counts.append(heavy_output_counts)\n",
        "    print(\"\\nMean heavy output probability:\", sum(heavy_output_counts) / ntrials / nshots)\n",
        "\n",
        "    # Mitigated experiment.\n",
        "    heavy_output_counts_zne = []\n",
        "    for i in range(njobs_zne):\n",
        "        to_run = []\n",
        "        for circuit in circuits[i * step_zne: (i + 1) * step_zne]:\n",
        "            to_run.extend([scale_noise(circuit, scale_factor) for scale_factor in scale_factors])\n",
        "\n",
        "        print(\"\\r\", end=f\"Running QV batch {i + 1} / {njobs_zne} with {len(to_run)} circuit(s).\")\n",
        "        batched_counts = estimate_heavy_output(to_run, backend=backend, qubits=qubits, nshots=nshots_zne)\n",
        "\n",
        "        for i in range(len(batched_counts) // len(scale_factors)):\n",
        "            scaled_counts = batched_counts[i * len(scale_factors): (i + 1) * len(scale_factors)]\n",
        "            all_scaled_counts.append(scaled_counts)\n",
        "            zne_count = zne.inference.RichardsonFactory.extrapolate(scale_factors, scaled_counts)\n",
        "            heavy_output_counts_zne.append(zne_count)\n",
        "\n",
        "    print(\"\\nMean mitigated heavy output probability:\", sum(heavy_output_counts_zne) / ntrials / nshots_zne)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfJrg9RCCBP9"
      },
      "source": [
        "## Save data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RwzxaZ8CBP-"
      },
      "outputs": [],
      "source": [
        "if save_data:\n",
        "    np.savetxt(f\"all_raw_counts_{backend.name()}.txt\", all_raw_counts)\n",
        "    np.savetxt(f\"all_scaled_counts_{backend.name()}.txt\", all_scaled_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tSCcCYOKEVAe"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Qiskit v0.34.2 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
